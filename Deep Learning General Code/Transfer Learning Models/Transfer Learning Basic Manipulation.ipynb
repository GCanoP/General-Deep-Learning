{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF_Basic_Manipulation_Models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO34HwiK10X0S5vXEnwOJYs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JjZoQJEi7XOs"},"source":["___\n","# <font color='GoldenRod'>__1. Transfer Learning Basic Manipulation Models__</font>\n","<font size ='2'>__A Basic Approach for Pre-Trained Model Manipulation and Convolutional Block Activation.__</font>\n","\n","<font color='cadetblue' size='2'>__Concepto 1.__</font><font size = '2'> Si el conjunto de datos original con el que se entrenó la red neuronal preentrenada es suficientemente grande y general, entonces la jerarquía espacial de las características (features) aprendidas permite actuar al modelo como un modelo genérico del mundo visual.</font>\n","\n","<font color='IndianRed' size='2'>__Author:__</font><font size='2'> Gerardo Cano Perea </font>/<font color='IndianRed' size='2'>__Date:__</font><font size='2'> September 21, 2021 </font>\n","___"]},{"cell_type":"markdown","metadata":{"id":"YoLZ-_yl8KrG"},"source":["___\n","#### <font color='cornflowerblue'>__1.1 Pre-Trained Model as Feature Extraction.__ </font>\n","\n","<font size='2'> __Reutilización de la Base Convolucional.__ Los modelos convolucionales preentreados en Keras son: \n","*   Xception\n","*   VGG16 & VGG19\n","*   ResNet 50\n","*   Inception V3\n","*   InceptionResNetV2\n","*   MobileNet & MobileNeV2\n","*   DenseNet\n","*   NasNet\n","</font>\n","___"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMqyWBhT_V28","executionInfo":{"status":"ok","timestamp":1633498564406,"user_tz":300,"elapsed":13640,"user":{"displayName":"Gerardo Cano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_6papkO6sskH4Z9t9Bk7ah2AZsbXYfQL4PUUBQ=s64","userId":"01748233161447411912"}},"outputId":"9e4c0050-ea80-45b8-8d5a-126088ad5300"},"source":["# Importing the VGG16 Model. \n","from keras.applications.\n","pre_trained_model = VGG16()\n","pre_trained_model.summary()"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 5s 0us/step\n","553476096/553467096 [==============================] - 5s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"WJ0Q0JtsNLaO"},"source":["___\n","#### <font color='cornflowerblue'>__1.2 Pre-Trained Model as Feature Extractor Preprocessor.__ </font>\n","___"]},{"cell_type":"code","metadata":{"id":"1boERxFSAEA9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632269566631,"user_tz":300,"elapsed":499,"user":{"displayName":"Gerardo Cano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_6papkO6sskH4Z9t9Bk7ah2AZsbXYfQL4PUUBQ=s64","userId":"01748233161447411912"}},"outputId":"a38d334f-7a19-4648-e4c6-f1e6822400b5"},"source":["# Definin the Pre-Model Structure. \n","pre_model = VGG16(include_top=False, input_shape=(300,300,3))\n","pre_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 300, 300, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"6K11tKIje_Ki"},"source":["# Deactivate Trainable Properties in Layers. \n","for layer in pre_model.layers:\n","  layer.trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5atmMTpYdZ6f"},"source":["# Combining Pre-Model with Main Model.\n","from keras.models import Sequential\n","from keras.layers import InputLayer\n","from keras.layers import Flatten\n","from keras.layers import Dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Gwz7vaveLHb","executionInfo":{"status":"ok","timestamp":1632269567117,"user_tz":300,"elapsed":491,"user":{"displayName":"Gerardo Cano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS_6papkO6sskH4Z9t9Bk7ah2AZsbXYfQL4PUUBQ=s64","userId":"01748233161447411912"}},"outputId":"7395db5a-4ac9-41d3-fbdc-12eab7e5a2dc"},"source":["main_model = Sequential()\n","main_model.add(pre_model)\n","main_model.add(Flatten())\n","main_model.add(Dense(units=1024, activation='relu'))\n","main_model.add(Dense(units=10, activation='softmax'))\n","main_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 9, 9, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 41472)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              42468352  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 57,193,290\n","Trainable params: 57,193,290\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]}]}